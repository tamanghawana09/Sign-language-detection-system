---

# âœ‹ğŸ¤Ÿ Sign Language Detection System

A **Deep Learningâ€“based Sign Language Detection System** built with **TensorFlow/Keras** and deployed using **Streamlit**.
This project can recognize **sign language gestures** from images or webcam input using a trained **CNN model**.

---

## ğŸ“‚ **Project Structure**

```
old-sign-language-detection/
â”‚â”€â”€ dataset/                  # Training & testing dataset
â”‚â”€â”€ debug_crops/              # Debugging cropped images
â”‚â”€â”€ Documentation/            # Notes, reports, docs
â”‚â”€â”€ venv/                     # Virtual environment (ignored in GitHub)
â”‚â”€â”€ .gitignore                # Git ignore rules
â”‚â”€â”€ best_asl_model.h5         # Trained CNN model
â”‚â”€â”€ label_encoder.pkl         # Label encoder for gesture classes
â”‚â”€â”€ main.py                   # Streamlit app entry point
â”‚â”€â”€ old.py                    # Previous version of app
â”‚â”€â”€ pre-run.py                # Pre-run testing script
â”‚â”€â”€ debug.py                  # Debugging utility
â”‚â”€â”€ Model-training.ipynb      # **Main notebook for training**
â”‚â”€â”€ Sign Model Training.ipynb # Alternate training notebook
```

---

## ğŸ› ï¸ **Installation Guide**

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/sign-language-detection.git
cd sign-language-detection
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
venv\Scripts\activate      # On Windows
source venv/bin/activate   # On Mac/Linux
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

ğŸ’¡ If you donâ€™t have `requirements.txt`, create one with:

```txt
streamlit
tensorflow
opencv-python
numpy
pandas
scikit-learn
matplotlib
```

---

## â–¶ï¸ **Run the Application**

Start the Streamlit app with:

```bash
streamlit run main.py
```

ğŸŒ By default, the app runs at: **[http://localhost:8501](http://localhost:8501)**

---

## ğŸ“Š **Model Details**

* ğŸ§  **Trained Model:** `best_asl_model.h5`
* ğŸ· **Labels:** `label_encoder.pkl`
* ğŸ“’ **Training Notebook:** `Model-training.ipynb` (**main notebook**)

---

## ğŸ”„ **Workflow**

1. ğŸ“· Upload an image or enable webcam.
2. ğŸ§¹ Input is **preprocessed** using OpenCV.
3. ğŸ¤– The trained **CNN model** predicts the gesture.
4. ğŸ¯ Streamlit displays the **prediction result in real-time**.

---

## ğŸŒ **Future Enhancements**

* âœ¨ Extend to **continuous word/sentence recognition**.
* ğŸ“± Optimize with **TensorFlow Lite** for mobile deployment.
* â˜ï¸ Deploy to **Streamlit Cloud** or **Hugging Face Spaces**.

---

## ğŸ¤ **Contributing**

Contributions, issues, and feature requests are welcome!
Feel free to **fork this repo** and submit a pull request ğŸš€

---
